{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations: Clean Data\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "This dataset contains information about 891 people who were on board the ship when departed on April 15th, 1912. As noted in the description on Kaggle's website, some people aboard the ship were more likely to survive the wreck than others. There were not enough lifeboats for everybody so women, children, and the upper-class were prioritized. Using the information about these 891 passengers, the challenge is to build a model to predict which people would survive based on the following fields:\n",
    "\n",
    "- **Name** (str) - Name of the passenger\n",
    "- **Pclass** (int) - Ticket class\n",
    "- **Sex** (str) - Sex of the passenger\n",
    "- **Age** (float) - Age in years\n",
    "- **SibSp** (int) - Number of siblings and spouses aboard\n",
    "- **Parch** (int) - Number of parents and children aboard\n",
    "- **Ticket** (str) - Ticket number\n",
    "- **Fare** (float) - Passenger fare\n",
    "- **Cabin** (str) - Cabin number\n",
    "- **Embarked** (str) - Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "![Clean Data](../../img/clean_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic = pd.read_csv('../../../titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing for `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there 177 missing values in Age column, replace the empty values with the mean of the Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use .fillna() to input the missing values with the mean\n",
    "titanic['Age'].fillna(titanic['Age'].mean(), inplace = True)\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine `SibSp` & `Parch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAFuCAYAAAClYV9DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABEmUlEQVR4nO3dd3iUZdr+8e+VTkKHAIGE3ruQACL2hoJiF1RERbHh9uK+r7ruuu5v992+dhC7gl0RsHdESOi9t4QESEgISQip9++Pmc0iUqLO5Elmzs9x5GDmmWeGk0TJmYd77succ4iIiIiIyA8T4XUAEREREZFQoGItIiIiIhIAKtYiIiIiIgGgYi0iIiIiEgAq1iIiIiIiARDldYDvavTo0e69997zOoaIiIiIhC872sEGd8U6Ly/P6wgiIiIiIt/S4Iq1iIiIiEh9pGItIiIiIhIAKtYiIiIiIgGgYi0iIiIiEgAq1iIiIiIiAaBiLSIiIiISACrWIiIiIiIBoGItIiIiIhIAKtYiIiIiIgGgYi0iIiIiEgAq1iIiIiIiAaBiLSIiIiISAFFeBxCR8DFxxiKyCkpJbtGI5ycP9zqOiIhIQKlYi0idySooZVteidcxREREgkJLQUREREREAkDFWkREREQkAFSsRUREREQCQMVaRERERCQAVKxFRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAFSsRUREREQCQMVaRERERCQAVKxFRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAKK8DiBSlybOWERWQSnJLRrx/OThXscRERGREBLUK9ZmNtrMNpjZZjO7+xjnnGFmy81sjZl9Hsw8IlkFpWzLKyGroNTrKCIiIhJignbF2swigUeAc4EsIMPMZjvn1h52TnPgUWC0c26nmbUJVh4RERERkWAK5hXrYcBm59xW51w5MAsYd8Q51wBvOOd2Ajjn9gYxj4iIiIhI0ASzWHcAMg+7n+U/drieQAsz+8zMlpjZ9Ud7ITObYmaLzWxxbm5ukOKKiIiIiHx/wSzWdpRj7oj7UcBQYAxwPnCvmfX81pOcm+acS3XOpSYmJgY+qYiIiIjIDxTMXUGygJTD7icD2Uc5J885VwKUmNkXwCBgYxBziYiIiIgEXDCvWGcAPcysi5nFAOOB2Uec8zZwqplFmVk8MBxYF8RMIiIiIiJBEbQr1s65SjObCrwPRAJPOefWmNlt/scfd86tM7P3gJVANfCkc251sDKJiIiIiARLUAfEOOfmAfOOOPb4Eff/AvwlmDlERERERIJNI81FRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAFSsRUREREQCQMVaRERERCQAVKxFRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAFSsRUREREQCQMVaRERERCQAVKxFRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAFSsRUREREQCQMVaRERERCQAVKxFRERERAIgyusAInVhb9EhZi7KJKewFIDC0gqKDlXQJC7a42QiIiISKnTFWkLeisz9nPv3L/jHRxs5VFENQH5JORf++0uyCg56nE5ERERChYq1hLTKqmrueHEphaUV33osM7+UX7y6woNUIiIiEopUrCWkfbYhl137S4/5+MKt+WzeW1SHiURERCRUqVhLSNuaV3zCc+atzKGq2tVBGhEREQllevOihLSWCbEnPOfvH23iuYU7uKB/EmMGJpHWuSWREVYH6URERCSUqFhLSGuZULtdP/KKy3l+4Q6eX7iDNk1iuXCAr2QP7diCCJVsERERqQUVawlZ81bl8JNZy4/5eFQE/PL83uzIP8h7q3eTX1IOwN6iMp5ZsJ1nFmynXdO4mpJ9UkpzlWwRERE5JhVrCUnPLtjO/e+swfmXTp/aozVllVWkbysAID4mkpm3jGBQSnMAfn9xP77euo+5K3N4b81u9h/07SKy+8AhnvpqG099tY32zeIYMzCJMQPbMyi5GWYq2SIiIvJfKtYSUpxz/PWDDTzy6ZaaY1PP7M7Pz+uJmXHGXz5l+76DtG0aV1OqAaIiIzi1RyKn9kjkgUv689XmPOaszOH9NbspOlQJQHbhIaZ/uY3pX24juUUjxgxMYuyA9vTv0FQlW0RERFSsJXRUVFXzmzdW8dqSLADMfFeiJ57cueac2hTg6MgIzujVhjN6teGPlw5g/uZc5qzI4cO1eygq85XsrIJSnvh8K098vpVOreIZ418u0jdJJVtERCRcqVhLSDhYXskdLy7lsw25AMRERfCvqwdzwYCkH/S6MVERnNW7LWf1bsuhiiq+3JTHnJXZfLR2DyXlVQDs2HeQRz/bwqOfbaFr6wT/cpEkerVtopItIiISRlSspcHbV1zGTc9ksCKrEICmcVE8OSmNYV1aBvT3iYuO5Ny+bTm3r69kf7Yhlzkrs/l43V5KK3wle2teCQ99spmHPtlM9zaNGTMgibEDk+jRtklAs4iIiEj9o2ItDdrOfQeZ9HQ62/JKAGjXNI5nbxpGr3bBLbJx0ZGM7t+O0f3bUVpexacb9jJnZTafrN/LoYpqADbvLeZfH2/iXx9volfbJjVXsrslNg5qNhEREfGGirU0WKt3FXLD0xnkFZcB0L1NY567aRjtmzeq0xyNYiK5cEASFw5IoqSskk/W+0r2pxtyKa/0lewNe4rY8GERf/9wI32SmjJ2YBJjBiTRuXVCnWYVERGR4FGxlgZp/qY8bn1+cc0659ROLXhyUirN42M8zZUQG8VFg9pz0aD2FJdV8vG6PbyzIocvNuZSXuUr2etyDrAu5wB/eX8D/Ts0ZcyA9owZkETHVvGeZhcREZEfRsVaGpy3l+/iF6+uoKLKt0n1eX3b8u8JJxEXHelxsm9qHBvFuMEdGDe4AwcOVfDR2j3MXZnDF5tya7Kv3nWA1bsO8Of31jMouRljBvqufCe3UMkWERFpaFSspUGZ/sVWHpy3rub+NcM78sC4/kTW84mITeOiuWxIMpcNSabwYAUfrN3N3FU5zN+UR2W1r2SvyCpkRVYhf5y3npM6NmeMf3lJXS9tERERke8nqMXazEYD/wIigSedc3864vEzgLeBbf5Dbzjnfh/MTNIwVVc7/jhvHU/O31Zz7Gfn9uSus7o3uC3tmsVHc2VqClemplBQUs4Ha3czZ2UOC7bso8pfspft3M+ynfv5w9x1pHZqUXMlu23TOI/Ti4iIyLEErVibWSTwCHAukAVkmNls59zaI0790jk3Nlg5pOErr6zmF6+uYPaKbAAiDP546QDGD+vocbIfrkVCDFendeTqtI7sKy7j/TV7mLMym4Vb9+Hv2CzeUcDiHQX8fs5a0jq3ZOzAJEb3b0ebJirZIiIi9Ukwr1gPAzY757YCmNksYBxwZLEWOaaiQxXc/sJS5m/OAyAuOoKHJwzhnL5tPU4WeK0ax3LN8I5cM7wjuUVlvLdmN3NWZJO+PR/nwDlI35ZP+rZ87p+9huFdWjHGX7JbN471Or40EBNnLCKroJTkFo14fvJwr+OIiISUYBbrDkDmYfezgKP9LX6yma0AsoFfOOfWHHmCmU0BpgB07Njwr1JK7ewtOsQNT2WwNucAAM3jo5kxKY2hnVp4nCz4EpvEMnFEJyaO6MTeA4d4d/Vu5qzMJmN7AQDVDr7euo+vt+7jvrdXM7Jba8YMTOL8fu1omeDtzihSv2UVlNbs+y4iIoEVzGJ9tIWv7oj7S4FOzrliM7sQeAvo8a0nOTcNmAaQmpp65GtICNqaW8ykp9PJzC8FoEPzRjx70zC6twm/4SptmsYxaWRnJo3szO7CQ8xblcOcldks3bkf8JXs+ZvzmL85j3veWs0p3VszdoCvZDeLj/Y2vIiISBgJZrHOAlIOu5+M76p0DefcgcNuzzOzR82stXMuL4i5pJ5bnrmfm57JIL+kHIDe7Zrw7E3D9MY9oF2zOG4a1YWbRnVh1/5S3l2Vwzsrc1iRuR+AqmrHFxtz+WJjLv/71ipGdW/NmIHtObdvW5o1UskWEREJpmAW6wygh5l1AXYB44FrDj/BzNoBe5xzzsyGARHAviBmknru0w17ueOFpZRW+Aa/jOjakmnXp9I0TqXwSB2aN+LmU7ty86ldycw/6L+SncOqXYUAVFQ5Pt2Qy6cbcomJjOC0nr7lIuf0aUsTfT5FREQCLmjF2jlXaWZTgffxbbf3lHNujZnd5n/8ceAK4HYzqwRKgfHOOS31CFOvLs7k7jdW1Ww5N2ZgEn+/ahCxUfVr8Et9lNIynltP78atp3djx74S5q7KYc6KnJr16eVV1Xy0bi8frdtLTFQEZ/RMrCnZCbHazl5ERCQQgvod1Tk3D5h3xLHHD7v9MPBwMDNI/eec49HPtvCX9zfUHLthZGfuG9uXiHo++KU+6tQqgTvO6M4dZ3Rna25xzZXs9buLAN/2hR+s3cMHa/cQGxXBWb3bMGZgEmf1bkN8jEq2iIjI96XvouKpqmrH795Zw3Nf76g5dvcFvbn1tK4NbvBLfdQ1sTFTz+rB1LN6sHlvEXNX+nYX2bS3GICyymreXb2bd1fvplF0JGf1acPYAUmc2btNvRsRLyIiUt+pWItnDlVU8dOXl/Pu6t0AREUY/3fFQC4bkuxxstDUvU0TfnxOE358Tg827ilizops5qzMYat/67XSiirmrsxh7soc4mMiOadPW8YMTOL0nokq2SIiIrWgYi2eKCyt4JbnFpO+LR+A+JhIHrtuKKf3TPQ4WXjo2bYJPzuvFz89tyfrdxcxZ2U2c1fmsH3fQQAOllcxe0U2s1dk0zg2inP7tmXMgCRO7dlaa95FRESOQcVa6tzuwkNMeiqdDXt8a35bJcTw9I1pDExu7m2wMGRm9ElqSp+kpvzivF6syT7AnJU5zF2VXbOHeHFZJW8u28Wby3bRJC6K8/q2Y+zAJE7p3pqYqAiP/wQiIiL1h4q11KlNe4qY9FQ62YWHAOjYMp7nbhpG59YJHicTM6N/h2b079CMX4/uxapdhb6SvTKHXft9JbvoUCWvL83i9aVZNGsUzfn92jJ2YHtO7taK6EiVbBERCW8q1lJnFm/PZ/KziyksrQCgf4emPH3DMBKbxHqcTI5kZgxMbs7A5Ob85oLeLM/cz5yVOcxblUOO/4eiwtIKXlmcxSuLs2gRH83o/u0YO7A9w7u0JOoYJbuiqhqgZktFERGRUKJiLXXigzW7uWvmMsoqfcXq1B6teey6oTTWHsr1nplxUscWnNSxBf97YR+WZRbwzgpfyd5bVAZAwcEKZqZnMjM9k1YJMTUle1iXlkRGGBt2F3Hf26vJKvBd+d6Zf5A7XlzC/Rf3o00TTdQUEZHQoFYjQffSop3c89Yq/nOR8pLB7fm/KwZpfW4DFBFhDO3UkqGdWnLf2L4s3lHAnJXZzFu1m7xiX8neV1LOi4t28uKinbRuHMupPVrxwZo9lJRXfeO15q3azfrdRcyeOko/YImISEjQdzMJGucc//xoE//6eFPNsVtP68qvR/fW4JcQEBFhDOvSkmFdWvLbi/qRvi2fOSuzeW/1bvaVlAOQV1zGm8uyj/kaW3NLeCUjk5tGdamr2CIiIkGjYi1BUVlVzb1vr2ZmembNsXvH9mWyxwUquUWjb/wqgREZYZzcrRUnd2vF7y7ux6Jt+cxZmcN7q3MoOFhx3Oe+t2a3irWIiIQEFWsJuNLyKu6auYyP1u0BIDrS+NtVg7l4UHuPk8Hzk4d7HSHkRUVGcEr31pzSvTW/H9ePvve9R0XVsd+sWFZRdczHREREGhItcpWAKigp59onF9aU6saxUTx747B6Uaql7kVHRjC0U4vjnjMopXndhBEREQkyFWsJmKyCg1zx+AKW7twPQGKTWF6+dQQju7f2Nph46pZTux738T0HDlGt7fdERCQEqFhLQKzLOcDljy1gS24JAF1bJ/DG7SPp176Zx8nEa2f3acs9Y/oQeYw3rL6/Zg+/eWOVyrWIiDR4Ktbyg329ZR9XPf41ew74tlsbnNKc124fSUrLeI+TSX1x86ldmf/rM2kRHw34xtjPmJRKo+hIAF5enMn/vKlyLSIiDZuKtfwgc1fmMOmpdIrKKgE4q3cbXrplOC0TYjxOJvVNUrNGNI/3/XfRtFE0Z/dpy1M3pBEX7ftraFZGJve8vVrlWkREGiwVa/nenvlqG1NnLqXcP6b6qtRkpk0cSnyMNpuR2jm5WyuempRGrH9Y0EuLdnLf7NU4p3ItIiINj4q1fGfOOf783nruf2ct/+k/d53VnT9fPpCoSP0nJd/NyO6tmXFYuX5h4U5+O3uNyrWIiDQ4akHynVRUVfPzV1fw2GdbADCDB8b14+fn9cJM0xTl+xnVozXTr0+tGXP/3Nc7+N07a1WuRUSkQVGxllorKavk5mcX88bSXQDEREXw2LVDmHhyZ2+DSUg4rWfiN8r1Mwu28/s5KtciItJwqFhLreQVlzFh+kI+35gLQNO4KF6YPJzR/ZM8Tiah5PSeiTwxcSgx/iVFT3+1nQfnrlO5FhGRBkHFWk5o576DXPHYAlZmFQLQrmkcr942kmFdWnqcTELRmb3a8PjEIURH+pYWPTl/G//v3fUq1yIiUu+pWMtxrd5VyGWPfcX2fQcB6NGmMW/cMZJe7Zp4nExC2Vm92/LYtUNryvW0L7by5/c2qFyLiEi9pmItx/TlplyufuJr8orLAUjr3ILXbhtJ++aNPE4m4eCcvm155JohRPknNj7++Rb+8r7KtYiI1F8q1nJUby3bxY1PZ1BSXgXA+f3a8vzk4TTzT84TqQvn9WvHw4eV60c/28LfPtioci0iIvWSirV8y/QvtvKTl5dT6Z+Ad92Ijjx67VDi/OOnRerS6P7tePiak4j0l+uHP93MPz7a5HEqERGRb1OxlhrV1Y4H5qzlwXnrao794ryePDCuf02pEfHC6P5JPDThv+X63x9v4p8fbfQ4lYiIyDdp9rQAUFZZxS9fXcnsFdkAREYYf7y0P1endfQ4mYjPhQOSqHaOH89aTlW1458fbSLSjLvO7uF1NBEREUDFWoCiQxXc+vwSFmzZB0BcdASPXDOEs/u09TiZyDeNHdieagc/mbWMagd/+3AjERHGnWd29zqaiIiIinW423vgEDc8ncHanAMAtIiPZsYNaQzp2MLjZCJHd/Gg9jjn+OnLy6l28Jf3N2AGd5yhci0iIt5SsQ5jW3OLuf6pdLIKSgHo0LwRz00eRrfExh4nEzm+cYM7UO0cP3tlBc7B/723gUgzbj29m9fRREQkjKlYh6llOwu46ZkMCg5WANAnqSnP3JhG26ZxHicTqZ1LT0qmuhp+8ZqvXP+/d9cTYcYtp3X1OpqIiIQpFesw9Mn6Pdz54jJKK3x7VJ/ctRVPXD+UpnHao1oalsuHJlPtHL96fSXOwYPz1mEGN5+qci0iInVPxTrMvLI4k9+8sYoq/x7VYwcm8berBhEbpT2qpWG6MjUF5+BXr68E4A9z1xEZYdx4ShePk4mISLhRsQ4Tzjke+XQzf/3gv3v/3nhKZ+4d05cI7VEtDdxVaSlUOcdv3lgFwO/eWUuEGZNGdvY2mIiIhBUV6zBQVe24f/Yanl+4o+bYby7ozZTTumKmUi2hYcKwjjgH//Omr1z/dvYaIgwmntzZ22AiIhI2gjp50cxGm9kGM9tsZncf57w0M6sysyuCmSccHaqo4s4Xl9aU6qgI4+9XDeLW07upVEvIuWZ4Rx64pH/N/XvfXsMLh/1AKSIiEkxBu2JtZpHAI8C5QBaQYWaznXNrj3Len4H3g5UlXBUerOCW5xeTvi0fgPiYSB6/biin9Uz0OJlI8Ewc0QnnHPe9vQaAe95aTYQZ1wzXFFEREQmuYF6xHgZsds5tdc6VA7OAcUc57y7gdWBvELOEnZzCUq58YkFNqW6VEMOsKSNUqiUsXH9yZ+6/qG/N/f95cxWz0nd6mEhERMJBMIt1ByDzsPtZ/mM1zKwDcCnw+PFeyMymmNliM1ucm5sb8KChZtOeIi57dAEb9xQD0KlVPK/fPpKByc29DSZSh244pQv3jv1vuf7Nm6t4JSPzOM8QERH5YYJZrI+2gNcdcf+fwK+dc1XHeyHn3DTnXKpzLjUxUVdcjydjez5XPP41OYWHABjQoRmv3z6Szq0TPE4mUvcmj+rCPWP6AOAc/PqNlby2JMvjVCIiEqqCuStIFpBy2P1kIPuIc1KBWf430bUGLjSzSufcW0HMFbLeX7ObH81cRlllNQCn9mjN49cNJSFWm79I+Lr51K5UO8cf563HOfjlayuIMLhsSLLX0UREJMQEs3FlAD3MrAuwCxgPXHP4Cc65mgkOZvYMMEel+vt5YeEO7nt7Nf65L1x6Ugf+fPlAYqKCuvGLSIMw5bRuVDv407u+cv3zV1dg5huLLiIiEihBK9bOuUozm4pvt49I4Cnn3Bozu83/+HHXVUvtOOf4x0eb+PfHm2qO3Xp6V359fm8NfhE5zG2nd6PaOf7vvQ2+cv3KCiLMGDe4w4mfLCIiUgtBXSPgnJsHzDvi2FELtXPuhmBmCUWVVdXc89ZqZvnfkGUG947py02jNMpZ5GjuOKM71dWOv36wkWoHP315ORFmXDSovdfRREQkBGjxbQNVWl7F1JeW8vF63y6FMZER/O2qQSoIIicw9aweVDv4+4e+cv0Tf7keMzDJ62giItLAqVg3QAUl5dz0bAbLdu4HoElsFE9cP5SR3Vp7G0ykgfjR2T2oqnb86+NNVFU7fjRrGREGFwxQuRYRke9PxboOTZyxiKyCUpJbNOL5ycO/12tk5h9k0tPpbM0tAaBNk1ieuXEYfds3DWRUkZD3k3N64Jzj359spqracdfMZTxsMLq/yrWIiHw/2jKiDmUVlLItr4SsgtLv9fy12Qe4/LEFNaW6a2ICr98+UqVa5HswM356bk+mntkdgMpqx9SXlvH+mt0eJxMRkYZKxbqBWLAlj6uf+Jq9RWUAnNSxOa/dNpKUlvEeJxNpuMyMn5/Xk9vP6Ab8p1wv5cO1ezxOJiIiDZGKdQMwZ2U2NzyVQVFZJQBn927DSzePoGVCjMfJRBo+M+NX5/fi1tO7AlBR5bjjxSV8vE7lWkREvhsV63ru6a+2cdfMZZRX+aYpXp2awhMTh9IoJtLjZCKhw8y4e3RvbjnVt1VlRZXj9heW8ql/1x0REZHaULGup5xz/Ond9fzunbU4/zTFH53VnT9dPoCoSH3ZRALNzPifC/sw2b8PfHlVNbc+v4TPNqhci4hI7aih1UMVVdX8/NUVPP75FgAiDP5wSX9+dl4vzDRNUSRYzIx7xvThxlM6A75yPeX5JXy+MdfbYCIi0iCoWNczJWWVTH52MW8s3QVATFQEj147lOtGdPI4mUh4MDPuG9uXG0Z2BqC8spopzy3my00q1yIicnwq1vVIXnEZE6Yv5Av/1bGmcVG8ePNwRvdv53EykfBiZvz2or5M9P9AW1ZZzc3PLuarzXkeJxMRkfpMxbqe2LGvhMsfW8DKrEIAkprF8drtI0nr3NLjZCLhycz4/bh+XDu8I+Ar15OfzWDBFpVrERE5uuMWazMrMrMDx/qoq5ChblVWIZc/toAd+w4C0LNtY964YyQ92zbxOJlIeDMzHhjXnwnDfOX6UEU1Nz2Twddb9nmcTERE6qPjFmvnXBPnXFPgn8DdQAcgGfg18IegpwsDX2zM5eppX5NXXA7AsM4tefXWkSQ1a+RxMhEBiIgwHrykP+PTUoD/lutFW1WuRUTkm2q7FOR859yjzrki59wB59xjwOXBDBaKqqrdN359c1kWNz2TwcHyKgDO79eW5yYPo1l8tGcZReTbIiKMP146gKtSkwEorajixmcyyNie73EyERGpT2pbrKvM7FozizSzCDO7FqgKZrBQsmNfCZOfyWBnvm+px878g1z4ry/56csrqPSX7IkjOvHotUOJi9bgF5H6KCLC+NNlA7liqK9cHyyv4oan0lmsci0iIn61LdbXAFcBe/wfV/qPyQnsLjzEFY9/zcdHTHBbm/PfJeq/OK8nvx/Xj8gI7VEtUp9FRBh/vnwglw3pAEBJeRU3PJ3Bkh0FHicTEZH6oFbF2jm33Tk3zjnX2jmX6Jy7xDm3PcjZQsLjn28ht6jsmI+PHZjE1LN6aPCLSAMRGWH85YpBXHqSr1wXl1Uy6al0lu5UuRYRCXe1KtZm1tPMPjaz1f77A83snuBGCw3vrd593Mez95fWURIRCZTICOOvVw5i3OD2gL9cz0hneeZ+b4OJiIinarsUZDrwG6ACwDm3EhgfrFChpKS88riP/+eNiyLSsERGGH+7chAXDfKV66KySibOWMTKrP3eBhMREc/UtljHO+fSjzh2/MYoAAxKbn7cxwcmN6ubICIScFGREfzjqkGMGZAEQNGhSq57chGrdxV6nExERLxQ22KdZ2bdAAdgZlcAOUFLFUImj+pyzMcizZg0snPdhRGRgIuKjOCf4wdz4YB2ABw4VMm1KtciImGptsX6TuAJoLeZ7QJ+AtwWrFCh5MzebfifC3tz5IYfMVER/O2qQfRrryvWIg1ddGQE/xp/EqP7+cp1YWkF181YxJpslWsRkXBS22K9wzl3DpAI9HbOjXLO7QhirpAy5bRufP7LM2nuH/zSIj6ar359Fpf4dxUQkYYvOjKCf084ifP6tgVg/8EKrntyEesO21pTRERCW22L9TYzmwaMAIqDmCdkpbSMp0V8DADN42NIbBLrcSIRCbSYqAgevmYI5/TxleuCgxVc++Qi1u9WuRafiTMWceZfP2PijEVeRxGRIKhtse4FfIRvScg2M3vYzEYFL5aISMMUExXBI9eexNm92wCQX1LOtdMXsXFPkcfJpD7IKihlW14JWQXaalUkFNV2QEypc+4V59xlwElAU+DzoCYTEWmgYqMiefS6IZzZKxGAfSXlXDN9IZtUrkVEQlptr1hjZqeb2aPAUiAO34hzERE5itioSB67biin9/SV67ziciZMX8TmvSrXIiKhqraTF7fh2wnkS6C/c+4q59zrwQwmItLQxUVH8sTEoZzaozUAecVlTJi+iC25equKiEgoqu0V60HOuUudczOdcyVBTSQiEkLioiOZfn1qTbnOLSpjwrSFbFW5FhEJOcct1mb2K//NB83s30d+1EE+EZEG7z/l+pTurQDYW1TGhOkL2Zan6xQiIqHkRFes1/l/XQwsOcqHiIjUQlx0JE9en8bJXX3les8B35Xr7SrXIiIh47jF2jn3jv/mSufcs0d+1EE+EZGQ0Sgmkhk3pDKia0sAdh84xITpC9mxT+VaRCQU1HaN9d/NbL2ZPWBm/YKaSEQkhMXHRPHUDWkM6+Ir1zmFh5gwbSGZ+Qc9TiYiIj9UbfexPhM4A8gFppnZKjO7J5jBRERCVXxMFE/fkEZa5xYAZBceYrzKtYhIg1frfaydc7udc/8GbgOWA/cFK5SISKhLiI3i6RuHkdrJV6537S9lwvSFZBWoXIuINFS13ce6j5ndb2argYeBBUByUJOJiIS4xrFRPH1jGkM6Ngd8464nTF9I9n6NuxYRaYhqe8X6aaAAOM85d7pz7jHn3N4TPcnMRpvZBjPbbGZ3H+XxcWa20syWm9liMxv1HfM3KMktGtGldQLJLRp5HUVE6okmcdE8e9MwBqc0ByAzv5Tx0xaSU6hyLSLS0ESd6AQziwS2OOf+9V1e2P+8R4BzgSwgw8xmO+fWHnbax8Bs55wzs4HAK0Dv7/L7NCTPTx7udQQRqYeaxEXz3ORhTJyRzorM/ezMP8j4aQt5ecrJtGsW53U8ERGppRNesXbOVQGtzCzmO772MGCzc26rc64cmAWMO+K1i51zzn83AXCIiIShpnHRPHfTMAYmNwNgx76DTJi+kD0HDnmcTEREaqu2S0F2AF+Z2b1m9rP/fJzgOR2AzMPuZ/mPfYOZXWpm64G5wE1HeyEzm+JfKrI4Nze3lpFFRBqWZo2ief6m4fTv0BSAbXklTJi2kL0q1yIiDUJti3U2MMd/fpPDPo7HjnLsW1eknXNvOud6A5cADxzthZxz05xzqc651MTExFpGFhFpeJrFR/PC5OH0a+8r11vzSpgwfSF7i1SuRUTquxOusQZwzv3ue7x2FpBy2P1kfAX9WL/HF2bWzcxaO+fyvsfvJyISEprHx/DC5OFc8+Qi1uUcYEtuCddMX8TMW0aQ2CTW63giInIMtd1u71Mz++TIjxM8LQPoYWZd/OuzxwOzj3jd7mZm/ttDgBhg33f/Y4iIhJYWCTG8ePNwerfz/ePg5r3FXDN9IXnFZR4nExGRY6ntUpBfAL/0f9yLb0DM4uM9wTlXCUwF3gfWAa8459aY2W1mdpv/tMuB1Wa2HN8OIlcf9mZGEZGw1jIhhpduGVFTrjftLeba6YvYp3ItIlIv1XYpyJIjDn1lZp/X4nnzgHlHHHv8sNt/Bv5cmwwiIuGopf/K9YTpC9m4p5gNe4q49slFvHTLCFomfNfNmkREJJhquxSk5WEfrc1sNNAuyNlERARo1TiWl24ZQY82jQFYv9tXrgtKyj1OJiIih6vtUpAl+JZ+LMY3zvxnwORghRKR0KTpo99fa3+57u4v1+tyDnDtk4vYf1DlWkSkvjjuUhAzSwMynXNd/Pcn4VsXvR1Ye5ynioh8i6aP/jCJTWJ56ZbhjJ+2kK25Jaz1l+uXbh5Bs/hor+OJiIS9E12xfgIoBzCz04D/BzwLFALTghtNRESO1KZJHLNuGUHX1gkArMk+wHUzFlFYWuFxMhEROVGxjnTO5ftvXw1Mc8697py7F+ge3GgiInI0bZrG8dItI+jcKh6AVbsKuV7lWkTEcycs1mb2n+UiZwOH711dqx1FREQk8No1i2PmlBF08pfrFVmFTHoqnQOHVK5FRLxyomI9E/jczN4GSoEvwTfYBd9yEBER8UhSs0bMvGUEHVv6yvXyzP1MeiqdIpVrERFPHLdYO+ceBH4OPAOMOmx4SwRwV3CjiYjIibRv3oiZU0aQ0tK308qynfu54ekMissqPU4mIhJ+TrjdnnNuoXPuTedcyWHHNjrnlgY3moiI1EaH5r4r1//ZxnDJjgJueCpd5VpEpI7Vdh9rERGpx5JbxDPzlhF0aO4r14t3FHDT0xmUqFyLiNQZFWsRkRCR0tJXrts3iwMgfXs+Nz2TwcFylWsRkbqgYi0iEkI6topn5pQRJPnL9aJtvnJdWl7lcTIRkdCnYi0iEmI6tUpg5i0jaNfUV64Xbs3n2icXcs+bq9hVUApAwcFy8ks0Dl1EJJBUrEVEQlDn1gnMnDKCNk1iAVi6cz8vLNpJeVU1APsPVnDhv75kx76S472MiIh8ByrWIiIhqkvrBJ65MQ2zoz+++8AhfvXayroNJSISwlSsRURC2Ka9xdRMIDiKRdvy2ZJbXHeBRERCmIq1iEgI27nv4AnPWZW1P/hBRETCgIq1iEgIa9M09oTn/OyVFdzy3GI+XreHSv8abBER+e5UrEVEQtgFA5KIj4k87jnVDj5cu4fJzy5m1J8/5W8fbCAz/8RXukVE5JtUrEVEQljTuGgevLQ/R3v/YnxMBLec2oXe7ZrUHNt94BAPfbKZ0/7yKRNnLGLuyhzKK3UVW0SkNqK8DiAiIsF16UnJtG/WiOlfbuWT9XupdtA4Noq3p55Ct8TGOOdYkVXIrPSdzF6RzcHyKpyDLzfl8eWmPFomxHD5kA5cndaR7m0ae/3HERGpt1SsRUTCwPCurRjetRVn/vUztuWVkNgklm6JvpJsZgxOac7glObcM7Yvc1ZkMysjk+WZ+wHILyln+pfbmP7lNtI6t+DqtI6MGZBEoxMsMRERCTcq1iIiUqNxbBTjh3Vk/LCOrMs5wMsZmby5bBeFpRUAZGwvIGN7Ab+bvYZxJ7VnfFpH+ndo5nFqEZH6QcVaRESOqk9SU+6/uB93X9Cb99fsZmb6ThZuzQegqKySFxbu5IWFO+nfoSnj0zpy8eD2NI2L9ji1iIh3VKxFROS44qIjGTe4A+MGd2BbXgkvZ2Ty2pIs8orLAFi96wD37FrNg3PXMWZgEuPTUhjaqQV2rJGPIiIhSsVaRERqrUvrBO6+oDc/P68nH6/by8sZO/l8Yy7VDkorqnhtSRavLcmie5vGjE9L4bIhybRMiPE6tohInVCxFhGR7yw6MoLR/dsxun87sveX8uriLF5ZnMmu/aUAbN5bzB/mruPP763nvH7tmJDWkZHdWhERoavYIhK6VKxFROQHad+8ET8+pwdTz+rO/M15zErfyYdr91BZ7aiocsxdmcPclTmktGzE1akpXDE0hXbN4ryOLSIScCrWIiISEJERxuk9Ezm9ZyJ5xWW8viSLlzMy2ZpXAkBmfil//WAjf/9wI2f2asP4YR05s1ciUZGaVSYioUHFWkREAq5141huPb0bU07rSvq2fF7OyGTuqhzKKqupdvDx+r18vH4vbZrEcmVqMlendqRjq3ivY4uI/CAq1iIiEjRmVjOc5rcX9ePtFbuYmZ7JupwDAOwtKuORT7fwyKdbOKV7K65O68j5/doSG6XhMyLS8KhYi4hInWgWH831J3dm4ohOrNpVyMz0TGYv30VJeRUAX23ex1eb99EiPprLhiQzPi2FHm2beJxaRKT2VKxFRKROmRkDk5szMLk594zpw9yVOczK2MnSnfsBKDhYwYz525gxfxtDO7Xg6rQUxg5MIj5G37JEpH7T31IiIuKZhNgorkpL4aq0FDbsLuLljEzeWJbF/oO+EepLdhSwZEcBv39nLRcPbs/4tBQGdGim4TMiUi+pWIuISL3Qq10T7ruoL78a3YsP1u5hVvpOFmzZB0BxWSUvLdrJS4t20jepKeOHpTBucAeaNdIIdRGpP1SsRUSkXomLjuTiQe25eFB7duzzjVB/dUkWuUW+Eeprcw5w39trfCPUByQxflhH0jprhLqIeC+om4ea2Wgz22Bmm83s7qM8fq2ZrfR/LDCzQcHMIyIiDUunVgn8anRvvr77LKZNHMrZvdvwn+GNZZXVvLFsF1c98TVn//1zpn2xhbziMm8Di0hYC9oVazOLBB4BzgWygAwzm+2cW3vYaduA051zBWZ2ATANGB6sTCIi0jBFRUZwXr92nNevHTmFpby2OIuXF2eSVeAbob41t4Q/zlvPX97fwLl923J1WkdO7d5aI9RFpE4FcynIMGCzc24rgJnNAsYBNcXaObfgsPMXAslBzCMiIiEgqVkj7jq7B3ee2Z2vtuQxKz2TD9bupqLKN0J93qrdzFu1mw7NG3FVagpXpSWT1KyR17FFJAwEs1h3ADIPu5/F8a9GTwbePdoDZjYFmALQsWPHQOUTEZEGLCLCOLVHIqf2SGRfcRlvLN3FrIydbMn1jVDftb+Uf3y0kX99vJHTeyYyflhHzurdhmiNUBeRIAlmsT7av7+5o55odia+Yj3qaI8756bhWyZCamrqUV9DRETCV6vGsdxyWlduPrULi3cUMCs9k7mrsjlU4Ruh/umGXD7dkEtik1iuGJrM1akpdG6d4HVsEQkxwSzWWUDKYfeTgewjTzKzgcCTwAXOuX1BzCMiIiHOzEjr3JK0zi2576K+zF6Rzaz0nazJ9o1Qzy0q47HPtvDYZ1s4uWsrxg9L4fx+7YiL1gh1EfnhglmsM4AeZtYF2AWMB645/AQz6wi8AUx0zm0MYhYREQkzzRpFM3FEJyaO6MTqXYXMTN/J7OXZFJVVAvD11n18vXUfzRpFc+lJHZgwrCO92mmEuoh8f0Er1s65SjObCrwPRAJPOefWmNlt/scfB+4DWgGP+vcfrXTOpQYrk4iIhKf+HZrx4KUD+F//CPWXMzJZvKMAgMLSCp5ZsJ1nFmxncEpzJgxLYezA9iTEatSDiHw3Qf1bwzk3D5h3xLHHD7t9M3BzMDOIiIj8R3xMFFempnBlagqb9vhGqL++NIsC/wj15Zn7WZ65v2aE+tVpHRmUrBHqIlI7+nFcRETCUo+2TbhnbF9+OboXH67dw6z0TOZvzgOgpLyKmemZzEzPpHe7JoxPS+GSkzrQPD7G49QiUp+pWIuISFiLjYpk7MD2jB3Ynsz8g/4R6pnsOeCb4rh+dxH3v7OWP767ngv7t+PqtI6M6NpSV7FF5FtUrEVERPxSWsbzi/N78ZNzevDZhlxmZWTy6Ya9VFU7yiureWt5Nm8tz6ZL6wSuSk3hiqHJJDaJ9Tq2iNQTKtYiIiJHiIqM4Jy+bTmnb1v2HDjEa0uymJWxk8x83wj1bXkl/Pm99fztgw2c3acN44d15LQeiURqhLpIWFOxFhEROY62TeO488zu3H56N77euo+Z6Tv5YM0eyquqqax2vL9mD++v2UP7ZnFcmZrCVWkpdGiuEeoi4UjFWkREpBYiIoxTurfmlO6tyS8p542lWczKyGTz3mIAsgsP8a+PN/HvTzZxWo9EJgxL4ew+bYmOjKC4rJIZX24jM/8g4Bu3/nLGTq4cmkKErnKLhAwVaxERke+oZUIMN5/alcmjurB0p2+E+pyVOZRWVOEcfL4xl8835tK6cQwXDWzPF5ty2ZJbUvP88spqfv36KhZty+dvVw7SGyFFQkSE1wFEREQaKjNjaKeW/OXKQaT/79k8eGl/BnRoVvN4XnE5Ty/Y/o1Sfbg3lu7i0w176yquiASZirWIiEgANImL5trhnXjnrlHMuWsUE0d0okncif9h+LUlWXWQTkTqgoq1iIhIgPXv0IwHLunPot+cfcJz/7Nftog0fCrWIiIiQRIfG0VKy+PvENIqQdMcRUKFirWIiEgQTRjW8biPL9iyjy825tZRGhEJJhVrERGRIJo8qgun9Uw85uPFZZVMejqdRz7dTHW1q8NkIhJoKtYiIiJBFBsVyVOTUvnrlYOIi/Z9242PieSpSWmMT0sBwDn4y/sbuPWFJRw4VOFlXBH5AVSsRUREgiwqMoIrhiaT1My33rpt0zjO6tOGP10+kD9dNoCYSN+34w/X7uGSh79i454iL+OKyPekYi0iIuKh8cM68uptJ9O+WRwAW/NKGPfwV7yzItvjZCLyXalYi4iIeGxQSnPeuWsUp3RvBUBpRRV3zVzGA3PWUlFV7XE6EaktFWsREZF6oFXjWJ69cRi3nd6t5tiM+du47slF5BZpr2uRhkDFWkREpJ6Iiozg7gt68/h1Q0iIiQRg0bZ8xj70JUt3FnicTkRORMVaRESknhndP4m3p46iW2IC4JvOePUTX/P8wh04py35ROorFWsREZF6qHubxrw9dRQXDmgHQEWV4963VvOLV1dyqKLK43QicjQq1iIiIvVU49goHrlmCP9zYW8izHfs9aVZXP7YAjLzD3obTkS+RcVaRESkHjMzppzWjRduHk6rhBgA1mQfYOxD8/lco9BF6hUVaxERkQZgZLfWvHPXKAalNAegsLSCG55O56GPN2kUukg9oWItIiLSQLRv3ohXbh3BNcM7Ar5R6H/7cCNTnl9MYalGoYt4TcVaRESkAYmNiuSPlw7g/64YSEyU79v4R+v2Mu7h+azffcDjdCLhTcVaRESkAboqNYXXbxtJh+aNANi+7yCXPrKAt5fv8jiZSPhSsRYREWmgBiQ34527RnFqj9aAbxT6j2ct53fvrNEodBEPqFiLiIg0YC0TYnjmxmHceeZ/R6E//dV2rp2+iL1FhzxMJhJ+VKxFREQauMgI45fn9+aJiUNpHBsFQPr2fMb+ez5LduR7nE4kfKhYi4iIhIjz+7Xj7amn0KNNYwD2FpVx9RMLeXbBdo1CF6kDKtYiIiIhpFtiY9668xTGDEgCoLLa8dvZa/jZKysoLdcodJFgUrEWEREJMQmxUTx8zUncM6YPkf5Z6G8u28Vljy1g5z6NQhcJFhVrERGREGRm3HxqV16YPJzWjX2j0NflHGDsQ1/y6fq9HqcTCU0q1iIiIiHs5G6teOeuUZzUsTkABw5VctOzGfzzo40ahS4SYCrWIiIiIS6pWSNmTRnBdSP+Owr9nx9t4ubnFlN4UKPQRQJFxVpERCQMxEZF8odLBvDXKwcR6x+F/sn6vVz8yHzW5WgUukggBLVYm9loM9tgZpvN7O6jPN7bzL42szIz+0Uws4iIiAhcMTSZ128fSXIL3yj0HfsOcumjX/HWMo1CF/mhglaszSwSeAS4AOgLTDCzvkeclg/8CPhrsHKIiIjIN/Xv0Ix3po7itJ6JAByqqOYnLy/n/tlrKK/UKHSR7yuYV6yHAZudc1udc+XALGDc4Sc45/Y65zIALfASERGpQy0SYnj6hjTuOqt7zbFnFmznmukL2XtAo9BFvo9gFusOQOZh97P8x74zM5tiZovNbHFubm5AwomIiIS7yAjj5+f1Yvr1qTTxj0JfvKOAMQ/NJ2O7RqGLfFfBLNZ2lGPfa18f59w051yqcy41MTHxB8YSERGRw53bty2z7xpFr7ZNAMgtKmPCtIU8/dU2jUIX+Q6CWayzgJTD7icD2UH8/UREROR76tI6gTfvHMlFg9oDvlHov3tnLT95eTkHyys9TifSMASzWGcAPcysi5nFAOOB2UH8/UREROQHiI+J4t/jB3Pv2L41o9DfXp7NZY8uYHteicfpROq/oBVr51wlMBV4H1gHvOKcW2Nmt5nZbQBm1s7MsoCfAfeYWZaZNQ1WJhERETk+M2PyqC68dPNwWjeOBWD97iIueng+H6/b43E6kfotqPtYO+fmOed6Oue6Oece9B973Dn3uP/2budcsnOuqXOuuf+2dqkXERHx2PCurZhz1yiG+EehFx2qZPKzi/n7hxqFLnIsmrwoIiIiR9WuWRyzppzM9Sd3qjn27483cdOzGew/WO5hMpH6ScVaREREjikmKoLfj+vP36/67yj0zzbkctHD81mTXehxOpH6RcVaRERETuiyIcm8ccdIUlr6RqFn5pdy2aMLeH1JlsfJROoPFWsRERGplX7tfaPQz+jlmylRVlnNz19dwb1vrdYodBFUrEVEROQ7aB4fw1OT0vjR2T1qjj2/cAfjp33N7kKNQpfwpmItIiIi30lEhPGzc3syY1IqTeJ8o9CX7tzP2Ifms2jrPo/TiXhHxVpERES+l7P7tOWdqaPo3c43Cj2vuIxrnlzEjPkahS7hScVaREREvrfOrRN4446RjBvsG4VeVe14YM5afjRLo9Al/KhYi4iIyA8SHxPFP68ezG8v6kuUfxT6OyuyufSRBWzTKHQJIyrWIiIi8oOZGTee0oWZU0aQ2MQ3Cn3DniIufmg+H63VKHQJDyrWIiIiEjBpnVsy965RpHZqAUBRWSU3P7eYv32wgSqNQpcQp2ItIiIiAdWmaRwv3TKCG0Z2rjn20CebufEZjUKX0KZiLSISRpJbNKJL6wSSWzTyOoqEuJioCO6/uB//uHoQcdG+uvHFxlzGPjSf1bs0Cl1CU5TXAUREpO48P3m41xEkzFx6UjK92zXltheWsGPfQbIKSrn8sQU8eOkArhia7HU8kYDSFWsREREJqj5JTZl95yjO6t0G8I1C/8WrK/jfN1dRVlnlcTqRwFGxFhERkaBrFh/Nk9en8tNzemK+Hfl4cdFOrn5iITmFpd6GEwkQFWsRERGpExERxo/P6cFTk9Jo6h+FvjxzPxc9NJ+vt2gUujR8KtYiIiJSp87s3YZ37hpFn6SmAOQVl3PdjEVM/2KrRqFLg6ZiLSIiInWuU6sE3rh9JJee1AHwjUJ/cN46ps5cRkmZRqFLw6RiLSIiIp5oFBPJ368axO8u7lczCn3uyhwueeQrtuQWe5xO5LtTsRYRERHPmBmTRnZm1pQRtPGPQt+0t5hxD3/F+2t2e5xO5LtRsRYRERHPpXZuyZwfjWJY55YAFJdVcuvzS/i/99ZrFLo0GCrWIiIiUi+0aRLHi7cM58ZTOtcce/SzLdzwdDr5JRqFLvWfirWIiIjUG9GREfz2on78a/xgGkVHAvDlpjwuemg+q7I0Cl3qNxVrERERqXfGDe7Am3eOpHOreAB27S/l8scX8EpGpsfJRI5NxVpERETqpd7tmvL21FGc08c3Cr28sppfvb6S37yhUehSP6lYi4iISL3VrFE00yam8vNz/zsKfWb6Tq56YiHZ+zUKXeoXFWsRERGp1yIijLvO7sHTN6TRrFE0ACv8o9AXbM7zOJ3If6lYi4iISINwRq82zLlrFH39o9D3lfhGoT/x+RaNQpd6QcVaREREGoyUlvG8ccdILh+SDEC1g//37nrufGkpxRqFLh5TsRYREZEGJS46kr9eOZAHLulPdKRv4fW8Vbu55JGv2LxXo9DFOyrWIiIi0uCYGRNHdGLWlJNp29Q3Cn3z3mIueeQr3lud43E6CVcq1iIiItJgDe3Ugjl3ncrwLv8dhX7bC0v507vrqayq9jidhBsVaxEREWnQEpvE8sLNw7l5VJeaY49/voVJT6ezr7jMw2QSblSsRUREpMGLjozgnrF9eWjCScTH+Eahf7V5Hxc9NJ8VmfsBOFRRxdrsA2zeW6xdRDySvb+U1bsKKSyt8DpKUER5HUBEREQkUC4a1J5e7Zpw6/NL2JZXQnbhIa58/GtO65nIkh35FBz0FbquiQn88rxeXDAgyePE4WH1rkJ+P2ct6dvyAYiJiuDiQe25d2zfmr3JQ0FQr1ib2Wgz22Bmm83s7qM8bmb2b//jK81sSDDziIiISOjr2bYJb089hXP7tgWgvKqaj9btqSnVAFtzS7j9xaXMWZntVcywsWlPEeOnLawp1eAbT//akiwmzlgUUuPpg3bF2swigUeAc4EsIMPMZjvn1h522gVAD//HcOAx/68iIiIi31vTuGieuG4oD85by4z524953u/fWUuPNk2I1OLYoHlg7tpj7jG+MquQOStyuHxoch2nCo5gLgUZBmx2zm0FMLNZwDjg8GI9DnjO+RY6LTSz5maW5JzTPjkiIiLyg0REGK0bxx33nL1FZZz/zy/qKJEczburd4dMsQ7mz2cdgMzD7mf5j33XczCzKWa22MwW5+bmBjyoiIiIhKbSitBZZhCqSitCZ2JmMK9Y21GOHfkW3Nqcg3NuGjANIDU1VW/jFRGRBim5RaNv/CrBNyi52XEfjzCYOKITcdGRdZQo/Ly6JIv8kvJjPj4ouXndhQmyYBbrLCDlsPvJwJHvEKjNOSIiIiHh+cl6G1FdO6NXG7olJrAlt+Soj08Y1pHfjetfx6nCS692TfjZKyuO+lhcdATXjuhUx4mCJ5hLQTKAHmbWxcxigPHA7CPOmQ1c798dZARQqPXVIiIiEiiREcaMSWl0aZ3wrcfO7t2Ge8f29SBVeLn0pA7cdVb3bx1vHBvFExNT6dA8dP4Fx4K5QbqZXQj8E4gEnnLOPWhmtwE45x43MwMeBkYDB4EbnXOLj/eaqampbvHi454iIiIi8g0VVdV8sGYPi3fkExMVwXl92zKkYwt8VUTqwva8Et5enk3BwXK6JSYw7qQONI1rsHtYH/U/nKAW62BQsRYRERERjx21WGvXRhERERGRAFCxFhEREREJABVrEREREZEAULEWEREREQkAFWsRERERkQBQsRYRERERCQAVaxERERGRAFCxFhEREREJABVrEREREZEAaHCTF80sF9jhdY4foDWQ53WIMKevgbf0+feevgbe0uffe/oaeCsUPv95zrnRRx5scMW6oTOzxc65VK9zhDN9Dbylz7/39DXwlj7/3tPXwFuh/PnXUhARERERkQBQsRYRERERCQAV67o3zesAoq+Bx/T5956+Bt7S5997+hp4K2Q//1pjLSIiIiISALpiLSIiIiISACrWIiIiIiIBoGJdh8xstJltMLPNZna313nCjZk9ZWZ7zWy111nCkZmlmNmnZrbOzNaY2Y+9zhROzCzOzNLNbIX/8/87rzOFKzOLNLNlZjbH6yzhxsy2m9kqM1tuZou9zhOOzOyn/r+DVpvZTDOL8zpTIKlY1xEziwQeAS4A+gITzKyvt6nCzjPAtzZzlzpTCfzcOdcHGAHcqf8H6lQZcJZzbhAwGBhtZiO8jRS2fgys8zpEGDvTOTc4VPdRrs/MrAPwIyDVOdcfiATGe5sqsFSs684wYLNzbqtzrhyYBYzzOFNYcc59AeR7nSNcOedynHNL/beL8BWLDt6mCh/Op9h/N9r/oXev1zEzSwbGAE96nUXEI1FAIzOLAuKBbI/zBJSKdd3pAGQedj8LlQoJU2bWGTgJWORxlLDiX4KwHNgLfOic0+e/7v0T+BVQ7XGOcOWAD8xsiZlN8TpMuHHO7QL+CuwEcoBC59wH3qYKLBXrumNHOaarRRJ2zKwx8DrwE+fcAa/zhBPnXJVzbjCQDAwzs/4eRworZjYW2OucW+J1ljB2inNuCL5lmXea2WleBwonZtYC37/WdwHaAwlmdp23qQJLxbruZAEph91PJsT++UPkRMwsGl+pftE594bXecKVc24/8Bl6z0FdOwW42My241sOeJaZveBtpPDinMv2/7oXeBPfMk2pO+cA25xzuc65CuANYKTHmQJKxbruZAA9zKyLmcXgW6w/2+NMInXGzAyYAaxzzv3d6zzhxswSzay5/3YjfN/g1nsaKsw4537jnEt2znXG9z3gE+dcSF2tq8/MLMHMmvznNnAeoF2i6tZOYISZxfu/J5xNiL2RV8W6jjjnKoGpwPv4/iN6xTm3xttU4cXMZgJfA73MLMvMJnudKcycAkzEd5Vuuf/jQq9DhZEk4FMzW4nvB/0PnXPa7k3CSVtgvpmtANKBuc659zzOFFb87+t4DVgKrMLXQ0NqvLlGmouIiIiIBICuWIuIiIiIBICKtYiIiIhIAKhYi4iIiIgEgIq1iIiIiEgAqFiLiIiIiASAirWISANnZv9rZmvMbKV/G8PhZvakmfX1P158jOeNMLNF/uesM7P76zS4iEiIifI6gIiIfH9mdjIwFhjinCszs9ZAjHPu5lo8/VngKufcCjOLBHoFM6uISKjTFWsRkYYtCchzzpUBOOfynHPZZvaZmaX+5yQz+5uZLTWzj80s0X+4DZDjf16Vc26t/9z7zex5M/vEzDaZ2S11/GcSEWmQVKxFRBq2D4AUM9toZo+a2elHOScBWOqcGwJ8DvzWf/wfwAYze9PMbjWzuMOeMxAYA5wM3Gdm7YP4ZxARCQkq1iIiDZhzrhgYCkwBcoGXzeyGI06rBl72334BGOV/7u+BVHzl/Brg8PHObzvnSp1zecCnwLBg/RlEREKF1liLiDRwzrkq4DPgMzNbBUw60VMOe+4W4DEzmw7kmlmrI885xn0RETmCrliLiDRgZtbLzHocdmgwsOOI0yKAK/y3rwHm+587xszMf7wHUAXs998fZ2Zx/qJ9BpAR8PAiIiFGV6xFRBq2xsBDZtYcqAQ241sW8tph55QA/cxsCVAIXO0/PhH4h5kd9D/3Wudclb9rpwNzgY7AA8657Dr4s4iINGjmnP51T0RE/su/n3Wxc+6vXmcREWlItBRERERERCQAdMVaRERERCQAdMVaRERERCQAVKxFRERERAJAxVpEREREJABUrEVEREREAkDFWkREREQkAP4/nhKyzYMRQ68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, col in enumerate(['SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sibsp and parch have similar trend. In both cases, the more spouse or children a passenager has, the less likely they are to survive. Hence I will combine both columns as one and name it Family_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_cnt'] = titanic['SibSp'] + titanic['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnnecessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the sibsp and parch has been combined, I need to drop them and also the passangerid as it won't help the prediction in anyway \n",
    "titanic.drop(['PassengerId', 'SibSp', 'Parch'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age            Ticket     Fare Cabin Embarked  Family_cnt  \n",
       "0    male  22.0         A/5 21171   7.2500   NaN        S           1  \n",
       "1  female  38.0          PC 17599  71.2833   C85        C           1  \n",
       "2  female  26.0  STON/O2. 3101282   7.9250   NaN        S           0  \n",
       "3  female  35.0            113803  53.1000  C123        S           1  \n",
       "4    male  35.0            373450   8.0500   NaN        S           0  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in missing & create indicator for `Cabin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Sex             0\n",
       "Age             0\n",
       "Ticket          0\n",
       "Fare            0\n",
       "Cabin         687\n",
       "Embarked        2\n",
       "Family_cnt      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to check survive rate based on cabin feature as I can't input the mean like I did in the Age cloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "False    0.666667\n",
       "True     0.299854\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(titanic['Cabin'].isnull())['Survived'].mean() # taking the average of the survived in this case is pretty much \n",
    "#the survival rate for each group-missing or non-missing cabin feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, the survival rate(<30%) was very low when the cabin feature is missing. This means that the passangers with no cabins actually do not have a cabin and hence were unlikely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "5         0       3                                   Moran, Mr. James   \n",
       "6         0       1                            McCarthy, Mr. Timothy J   \n",
       "7         0       3                     Palsson, Master. Gosta Leonard   \n",
       "8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9         1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex        Age            Ticket     Fare Cabin Embarked  Family_cnt  \\\n",
       "0    male  22.000000         A/5 21171   7.2500   NaN        S           1   \n",
       "1  female  38.000000          PC 17599  71.2833   C85        C           1   \n",
       "2  female  26.000000  STON/O2. 3101282   7.9250   NaN        S           0   \n",
       "3  female  35.000000            113803  53.1000  C123        S           1   \n",
       "4    male  35.000000            373450   8.0500   NaN        S           0   \n",
       "5    male  29.699118            330877   8.4583   NaN        Q           0   \n",
       "6    male  54.000000             17463  51.8625   E46        S           0   \n",
       "7    male   2.000000            349909  21.0750   NaN        S           4   \n",
       "8  female  27.000000            347742  11.1333   NaN        S           2   \n",
       "9  female  14.000000            237736  30.0708   NaN        C           1   \n",
       "\n",
       "   Cabin_ind  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1) # Here I am creating a cabin indicator for each passanger. 1 means is not missing. 0 means is missing.\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `Sex` to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since ml model doesn't know what a male or female is, I will convert the male and female in to numbers. 0 being male, female being 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  Sex  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris    0   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n",
       "2         1       3                             Heikkinen, Miss. Laina    1   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n",
       "4         0       3                           Allen, Mr. William Henry    0   \n",
       "\n",
       "    Age            Ticket     Fare Cabin Embarked  Family_cnt  Cabin_ind  \n",
       "0  22.0         A/5 21171   7.2500   NaN        S           1          0  \n",
       "1  38.0          PC 17599  71.2833   C85        C           1          1  \n",
       "2  26.0  STON/O2. 3101282   7.9250   NaN        S           0          0  \n",
       "3  35.0            113803  53.1000  C123        S           1          1  \n",
       "4  35.0            373450   8.0500   NaN        S           0          0  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_num = {'male': 0, 'female': 1} #this is a dictionary\n",
    "titanic['Sex'] = titanic['Sex'].map(gender_num)  #this will control the gender mapping\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop Cabin because I already have cabin_ind instead. I am dropping Embarked because it wasn't the really factor for surviving even there are correlation, sex and cabin indicator is more likely the causal factor for survival. Name and Ticket wasn't a causal factor either. So I am dropping them as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.drop(['Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is cleaned, it is time to save it and use it for further analysis and ml building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out cleaned data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "titanic.to_csv('../../../titanic_cleaned.csv', index=False) # save as csv using .to_csv and index = False means \n",
    "#ignore the index when saving the date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_clean = pd.read_csv('../../../titanic_cleaned.csv')\n",
    "titanic_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set\n",
    "\n",
    "![Split Data](../../img/split_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # import the sklearn train/split library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic_clean.drop('Survived', axis=1) # droping Survived the field or column because it is one I want to predict.\n",
    "labels = titanic_clean['Survived'] \n",
    "#Train and split the clean data\n",
    "#chossing test_size as 40% because I want to use 20% for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size =0.4, random_state = 42)\n",
    "\n",
    "#Set up the validation data with x_test as the features and y_test as the labels. \n",
    "#0.5 test_size means half of the test_size which is 20\n",
    "#change the X_train to X_val, and y_train to y_val\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size =0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check to make sure that 60% was store for training and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset)/len(labels), 2)) # this will represent the full clean dataset, round to 2 decimal place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### y_train has 60% of the data\n",
    "###### y_val has 20%\n",
    "###### y_test has 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out all data, save to file as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.to_csv('../../../train_features.csv', index=False)\n",
    "X_val.to_csv('../../../val_features.csv', index=False)\n",
    "X_test.to_csv('../../../test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../../../train_labels.csv', index=False)\n",
    "y_val.to_csv('../../../val_labels.csv', index=False)\n",
    "y_test.to_csv('../../../test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Hyperparameters\n",
    "\n",
    "Import [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression: Binary target variable\n",
    "###### It is more transparent \n",
    "###### Fairly well-behaved data\n",
    "###### Need a quick initial benchmark\n",
    "\n",
    "\n",
    "###### DO NOT USE  when the target variable is continuous\n",
    "###### DO NOT USE  when you have massive data\n",
    "###### DO NOT USE  with unwieldly data\n",
    "###### DO NOT USE  with data with alot of outliers, missing features, rarely the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The C hyperparameter is a regularization parameter in logistic regression that controls \n",
    "#### how closely the model fits to the traning data\n",
    "\n",
    "###### c = /lambda. Hence as lambda gets to zero, c goes to infinity which means high chances of overfiting\n",
    "###### because of low regularization, high complexity\n",
    "###### High lambda means small c which means high chances of underfitting becasue of high regularization and low complexity.\n",
    "\n",
    "#### Regularization is a technique used to reduce overfitting by discouraging overly complex models in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "![CV](../../img/CV.png)\n",
    "![Cross-Val](../../img/Cross-Val.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib #use to pickle the best model and save it out to be able to read it back in\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "tr_features = pd.read_csv('../../../train_features.csv')\n",
    "tr_labels = pd.read_csv('../../../train_labels.csv')# header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "0           1\n",
       "1           0\n",
       "2           1\n",
       "3           0\n",
       "4           1\n",
       "..        ...\n",
       "529         1\n",
       "530         0\n",
       "531         0\n",
       "532         1\n",
       "533         0\n",
       "\n",
       "[534 rows x 1 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_predict_proba_lr',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'sparsify']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(LogisticRegression) # see all the methods included with logisticregression object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![C](../../img/c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 1}\n",
      "\n",
      "0.67 (+/-0.077) for {'C': 0.001}\n",
      "0.708 (+/-0.098) for {'C': 0.01}\n",
      "0.777 (+/-0.134) for {'C': 0.1}\n",
      "0.8 (+/-0.118) for {'C': 1}\n",
      "0.794 (+/-0.116) for {'C': 10}\n",
      "0.794 (+/-0.116) for {'C': 100}\n",
      "0.794 (+/-0.116) for {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] #the hyperparameter settings for evaluating the model\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv = 5) # i am doing 5 fold cross validation\n",
    "cv.fit(tr_features, tr_labels.values.ravel()) # to change the labels to array from column vector\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_ # this is an actual model. the logisticregression model performed best at C=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model, save the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(cv.best_estimator_, '../../../LR_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines: Hyperparameters\n",
    "\n",
    "Import [Support Vector Machines](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A support Vector Machine. SVM is a classifier that finds an optimal hyperplane that maximize the margin\n",
    "###### between two classes.\n",
    "\n",
    "###### finding a line(in 2D but called a hyperplane in nD space) that is evenly spaced between group points\n",
    "\n",
    "\n",
    "###### The kernel trick: A.K.A kernel method, transforms data that is not linearly separable in n-dimensional space\n",
    "###### to a higher dimension where it is linearly separable.\n",
    "\n",
    "\n",
    "## Guidelines for using SVM:\n",
    "\n",
    "###### Use for Binary target varable\n",
    "###### Feature-to-row ratio is very high\n",
    "###### very complex relations\n",
    "###### best for data with lots of outliers\n",
    "\n",
    "\n",
    "## DO NOT USE when:\n",
    "###### Feature-to-row ratio is very low\n",
    "###### Transparency is importance or interested in significance of predictors\n",
    "###### looking for a quick benchmark model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The C hyperparameter is a penalty term determines how closely the model fits to the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![c_svm](../../img/c_svm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.796 (+/-0.115) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.654 (+/-0.06) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 1, 'kernel': 'linear'}\n",
      "0.661 (+/-0.048) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 10, 'kernel': 'linear'}\n",
      "0.684 (+/-0.07) for {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv_svm = GridSearchCV(svc, parameters, cv = 5)\n",
    "cv_svm.fit(tr_features, tr_labels.values.ravel())\n",
    "print_results(cv_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_svm.best_estimator_ # this the SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Save the SVM model using joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(cv_svm.best_estimator_, '../../../SVM_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Hyperparameters\n",
    "\n",
    "Import [`MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) and [`MLPRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A multilayer perceptron is a classic feed-forward artificial neural network, the core component of deep learning\n",
    "##### Or it is a connected series of nodes(in the form of a directed acyclic graph), where each node represents a function or a model.\n",
    "\n",
    "\n",
    "## Use Multilayer Perceptron when:\n",
    "##### Categorical or continuous target variable\n",
    "##### Very complex relationships or performance is the only thing that matters\n",
    "##### Control over the training process is very important\n",
    "\n",
    "## DO NOT USE when:\n",
    "\n",
    "##### Image recognitions, time series, etc. use CNN instead\n",
    "##### Transparency is important or insterested in significance of predictors. because it is like blackbox. don't really know what's going on instead the blackbox.\n",
    "\n",
    "##### Need a quick benchmark model. requires lots of time to train\n",
    "##### Limited data available. better off with SVM or logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Multilayer Perceptron Algorithm for Classification & Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Multilayer Perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hidden layer-size hyperparameter determines how many hidden layers there will be and how many nodes in each layer.\n",
    "\n",
    "##### Activation Function- hyperparameter dictates the type of nonlinearity that is introduced to the model.\n",
    "\n",
    "##### The Learning rate- hyperparameter facilitates both how quickly and whether or not the algorithm will find the optimal solution. small learning rate takes long but it will find optimal solution eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![hidden layer](../../img/hidden_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "\n",
      "0.721 (+/-0.078) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.732 (+/-0.159) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.713 (+/-0.07) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.802 (+/-0.104) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.792 (+/-0.128) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.794 (+/-0.087) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.785 (+/-0.075) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.803 (+/-0.113) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.785 (+/-0.152) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.729 (+/-0.119) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.706 (+/-0.099) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.68 (+/-0.088) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.781 (+/-0.132) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.783 (+/-0.09) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.774 (+/-0.114) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.809 (+/-0.088) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.8 (+/-0.101) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.798 (+/-0.098) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.68 (+/-0.095) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.697 (+/-0.106) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.714 (+/-0.127) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.768 (+/-0.119) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.764 (+/-0.119) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.758 (+/-0.094) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.781 (+/-0.123) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.785 (+/-0.097) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.789 (+/-0.109) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)], #using 1 hidden layer\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "cv_mlp = GridSearchCV(mlp, parameters, cv = 5)\n",
    "cv_mlp.fit(tr_features, tr_labels.values.ravel())\n",
    "print_results(cv_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mlp.best_estimator_ # this is the mlp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(cv_mlp.best_estimator_, '../../../MLP_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Hyperparameters\n",
    "\n",
    "Import [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Random Forest Algorithm for Classification & Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE when:\n",
    "\n",
    "###### Categorical or continuous target variable\n",
    "###### Interested in significance of predictors\n",
    "###### Need a quick benchmark model\n",
    "###### If you have messy data, such as missing values, outliers\n",
    "\n",
    "#### DO NOT USE SUGGESTION-when:\n",
    "\n",
    "###### If you're solving a very complex, novel problem(might not be the right tools)\n",
    "###### Transparency is important\n",
    "###### Prediction time is important\n",
    "###### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The n_estimators hyperparameter controls how many individual decision trees will be built.-->width\n",
    "##### The max_depth hyperparameter controls how deep each individual tree can go.-->depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![RF](../../img/rf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 4, 'n_estimators': 250}\n",
      "\n",
      "0.785 (+/-0.12) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.798 (+/-0.102) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.798 (+/-0.134) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.8 (+/-0.093) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.818 (+/-0.12) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.828 (+/-0.118) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.824 (+/-0.058) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.826 (+/-0.077) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.809 (+/-0.083) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.8 (+/-0.049) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.815 (+/-0.034) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.813 (+/-0.04) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.811 (+/-0.042) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.813 (+/-0.036) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.809 (+/-0.028) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.781 (+/-0.043) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.811 (+/-0.024) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.807 (+/-0.022) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250], # number of trees to build\n",
    "    'max_depth': [2, 4, 8, 16, 32, None] # how deep the tree can go\n",
    "}\n",
    "\n",
    "cv_rf = GridSearchCV(rf, parameters, cv = 5)\n",
    "cv_rf.fit(tr_features, tr_labels.values.ravel())\n",
    "print_results(cv_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The random forest model has 82.6% prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=250)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf.best_estimator_ # this is the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model, save the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(cv_rf.best_estimator_, '../../../RF_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting: Hyperparameters\n",
    "\n",
    "Import [`GradientBoostingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) and [`GradientBoostingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting is an emsemble method that aggregates a number of weak models create one strong model\n",
    "\n",
    "\n",
    "###### A weak model is one that is only slightly better than random guessing. A strong model is one that is strongly correlated with true classification\n",
    "\n",
    "\n",
    "#### Boosting effectively learns from its mistakes with each iteration.\n",
    "\n",
    "\n",
    "### Difference between Random Forest and Boosting\n",
    "##### Each decision tree or model in Random Forest was built independently\n",
    "##### Whereby in Boosting, each model learns from the mistake of previous model before it so there aren't independent\n",
    "\n",
    "\n",
    "\n",
    "### When to USE:\n",
    "#### Categorical or continuous target variable\n",
    "#### Useful on nearly any type of problem\n",
    "#### Interested in Significance of predictors\n",
    "#### Prediction time is important\n",
    "\n",
    "### DO NOT USE when:\n",
    "##### Transparency is important\n",
    "##### Training time is important or compute power is limited\n",
    "##### Data is really noisy (has a tendancy to overfit since it constantly learning from previous models mistake)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "![GB](../../img/gb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Boosting Algorithm for Classification & Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.811 (+/-0.117) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.811 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.83 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.841 (+/-0.077) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.822 (+/-0.052) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.818 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.83 (+/-0.049) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.817 (+/-0.049) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.817 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.807 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.624 (+/-0.007) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.803 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.802 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.788 (+/-0.041) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.796 (+/-0.115) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.815 (+/-0.119) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.818 (+/-0.111) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.828 (+/-0.092) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.813 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.839 (+/-0.076) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.826 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.809 (+/-0.04) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.813 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.82 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.805 (+/-0.029) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.796 (+/-0.034) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.818 (+/-0.056) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.79 (+/-0.016) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.805 (+/-0.035) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.796 (+/-0.025) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.8 (+/-0.048) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.79 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.792 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.792 (+/-0.044) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.818 (+/-0.099) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.832 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.826 (+/-0.077) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.822 (+/-0.081) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.824 (+/-0.057) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.796 (+/-0.037) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.788 (+/-0.043) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.79 (+/-0.028) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.794 (+/-0.039) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.785 (+/-0.045) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.794 (+/-0.039) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.792 (+/-0.038) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.787 (+/-0.054) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.79 (+/-0.033) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.796 (+/-0.047) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.815 (+/-0.04) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.796 (+/-0.029) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.79 (+/-0.053) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.788 (+/-0.045) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.794 (+/-0.04) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.204 (+/-0.115) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.307 (+/-0.195) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.443 (+/-0.253) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.423 (+/-0.268) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.395 (+/-0.261) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.395 (+/-0.187) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.635 (+/-0.108) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.573 (+/-0.204) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.573 (+/-0.173) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.597 (+/-0.153) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.693 (+/-0.133) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.719 (+/-0.098) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.712 (+/-0.149) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.723 (+/-0.117) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.376 (+/-0.007) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.29 (+/-0.102) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.359 (+/-0.189) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.35 (+/-0.18) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.35 (+/-0.193) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.354 (+/-0.195) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.556 (+/-0.116) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.571 (+/-0.16) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.543 (+/-0.122) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.564 (+/-0.104) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.665 (+/-0.08) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.668 (+/-0.088) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.667 (+/-0.07) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.665 (+/-0.059) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9], # more decision trees because they all weak\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv_gb = GridSearchCV(gb, parameters, cv = 5)\n",
    "cv_gb.fit(tr_features, tr_labels.values.ravel())\n",
    "print_results(cv_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the gb model has 84.1% prediction accuracy with learning rate of 0.01, max depth of 3 and n_estimators of 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.01, n_estimators=500)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb.best_estimator_ # This is the Gradient Boosting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(cv_gb.best_estimator_, '../../../GB_model_pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting: Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eXtreme Gradient Boosted trees\n",
    "#### Remember boosting is an ensemble method\\\n",
    "#### Parallell processing\n",
    "#### Can cross-validate at each iteration\n",
    "##### Enables early stopping, finding optimal number of iteration\n",
    "#### Incremental training\n",
    "#### Can plug in your own optimization objectives\n",
    "#### Tree pruning\n",
    "##### Generally results in deeper, but optimized trees.\n",
    "\n",
    "\n",
    "## The Hyperparameters\n",
    "##### 1. Booster\n",
    "######   gbtree or gblinear\n",
    "##### 2. Objective(ie, multi:softmax, multi:softprob). softmax for best classification\n",
    "##### 3. Eta(learning rate-adjusts weights on each step). in reality 0.2 may give better result\n",
    "##### 4. Max_depth(depth of the tree) if small the model may underfit, if too big the model may overfit\n",
    "##### 5. Min_child_weight--> used to control the model from overfitting. if too high the model may underfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "param = {\n",
    "         'objective':['binary:logistic'], # binary since it is classific problem\n",
    "         'n_estimators': [5, 50, 250],\n",
    "         'eta': [0.05, 0.1, 0.2, 0.3], #so called `eta` value\n",
    "         'max_depth': [2, 4, 6, 8],\n",
    "         'random_state': [42],\n",
    "         'disable_default_eval_metric': ['True']\n",
    "         \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I will be using the randomizedSearchCV instead because the GridSearchCV when used with xgboost has no .best_estimator_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 50, 'max_depth': 2, 'eta': 0.2, 'disable_default_eval_metric': 'True'}\n",
      "\n",
      "0.832 (+/-0.076) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 50, 'max_depth': 4, 'eta': 0.05, 'disable_default_eval_metric': 'True'}\n",
      "0.83 (+/-0.035) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 4, 'eta': 0.05, 'disable_default_eval_metric': 'True'}\n",
      "0.822 (+/-0.066) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 50, 'max_depth': 8, 'eta': 0.2, 'disable_default_eval_metric': 'True'}\n",
      "0.841 (+/-0.091) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 50, 'max_depth': 2, 'eta': 0.2, 'disable_default_eval_metric': 'True'}\n",
      "0.809 (+/-0.061) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 8, 'eta': 0.1, 'disable_default_eval_metric': 'True'}\n",
      "0.833 (+/-0.041) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 2, 'eta': 0.2, 'disable_default_eval_metric': 'True'}\n",
      "0.815 (+/-0.08) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 4, 'eta': 0.3, 'disable_default_eval_metric': 'True'}\n",
      "0.792 (+/-0.109) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 5, 'max_depth': 2, 'eta': 0.1, 'disable_default_eval_metric': 'True'}\n",
      "0.807 (+/-0.072) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 4, 'eta': 0.2, 'disable_default_eval_metric': 'True'}\n",
      "0.805 (+/-0.074) for {'random_state': 42, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 8, 'eta': 0.05, 'disable_default_eval_metric': 'True'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "random_search_xgb = RandomizedSearchCV(xgb_model, param, cv = 5)\n",
    "random_search_xgb.fit(tr_features, tr_labels.values.ravel())\n",
    "print_results(random_search_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the Xgboost model prediction accuracy of 84.3% with n_estimator of 250, and eta(a.k.a learning rate) of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1,\n",
       "              disable_default_eval_metric='True', enable_categorical=False,\n",
       "              eta=0.2, gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.200000003,\n",
       "              max_delta_step=0, max_depth=2, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_xgb.best_estimator_ # this is the xgboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the xgboost model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(random_search_xgb.best_estimator_, '../../../XGBoost_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "##### How does the model handle data of different sizes, such as short and fat, long and skinny data?. if alot of features, few rows use SVM\n",
    "##### How does the model handle the complexity of feature relationship? if too complex maybe consider MLP, Gradient Boosting\n",
    "##### How does the model handle messy data? if alot of outliers SVM is probable a good choice. GB is not because it might overfit to the outliers\n",
    "\n",
    "### Latency\n",
    "##### How long will the model take to train. for limit time, use logistic regression\n",
    "##### How long will it take to predict. consider gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from time import time\n",
    "val_features = pd.read_csv('../../../val_features.csv')\n",
    "val_labels = pd.read_csv('../../../val_labels.csv') #, header=None)\n",
    "\n",
    "te_features = pd.read_csv('../../../test_features.csv')\n",
    "te_labels = pd.read_csv('../../../test_labels.csv') #, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for mdl in ['LR', 'SVM', 'MLP', 'RF']: #, 'GB', 'XGBoost']: # load all the model using for loop\n",
    "    models[mdl] = joblib.load('../../../{}_model.pkl'.format(mdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models on the validation set\n",
    "\n",
    "![Evaluation Metrics](../../img/eval_metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.775 / Precision: 0.712 / Recall: 0.646 / Latency: 11.8ms\n",
      "SVM -- Accuracy: 0.747 / Precision: 0.672 / Recall: 0.6 / Latency: 5.9ms\n",
      "MLP -- Accuracy: 0.775 / Precision: 0.712 / Recall: 0.646 / Latency: 3.5ms\n",
      "RF -- Accuracy: 0.809 / Precision: 0.792 / Recall: 0.646 / Latency: 8.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest -- Accuracy: 0.804 / Precision: 0.836 / Recall: 0.671 / Latency: 6.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('Random Forest', models['RF'], te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
